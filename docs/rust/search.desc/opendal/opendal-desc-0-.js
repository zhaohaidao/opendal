searchState.loadedDescShard("opendal", 0, "Apache OpenDAL™ is an Open Data Access Layer that …\naliyun_drive: Aliyun Drive services.\nalluxio: Alluxio services.\nThe given path already exists thus we failed to the …\natomicserver: Atomicserver services.\nazblob: Azure Storage Blob services.\nAzdls: Azure Data Lake Storage Gen2.\nazfile: Azfile Services\nB2: Backblaze B2 Services.\nBlockingDeleter is designed to continuously remove content …\nBlockingLister is designed to list entries at given path …\nBlockingOperator is the entry for all public blocking APIs.\nBlockingReader is designed to read data from given path in …\nBlockingWriter is designed to write data into given path …\nBuffer is a wrapper of contiguous <code>Bytes</code> and non-contiguous …\nBufferIterator is an iterator of buffers.\nBufferSink is the adapter of <code>futures::Sink</code> generated by …\nBuilder is used to set up underlying services.\nAssociated builder for this configuration.\ncacache: cacache backend support.\nCapability defines the supported operations and their …\nChainsafe: Chainsafe Services.\ncloudflare-kv: Cloudflare KV services.\nCompfs: Compio fs Services.\nThe condition of this operation is not match.\nAssociated configuration for this builder.\nThe config for backend is invalid.\nConfigurator is used to configure the underlying service.\ncos: Tencent Cloud Object Storage services.\nCustom that allow users to implement services outside of …\nd1: D1 services\nDIR means the path can be listed.\ndashmap: dashmap backend support.\ndbfs: DBFS backend support.\nDeleteInput is the input for delete operations.\nDeleter is designed to continuously remove content from …\ndropbox: Dropbox services.\nEntry returned by <code>Lister</code> or <code>BlockingLister</code> to represent a …\nEntryMode represents the mode.\nContains the error value\nError is the error struct returned by all opendal …\nErrorKind is all kinds of Error of opendal.\netcd: Etcd Services\nExecute trait is used to execute task in background.\nExecutor that runs futures in background.\nFILE means the path has data to read.\nfoundationdb: Foundationdb services.\nfs: POSIX-like file system.\nftp: FTP backend.\nFuturesAsyncReader is the adapter of <code>AsyncRead</code>, …\nFuturesIoAsyncWriter is the adapter of <code>AsyncWrite</code> for …\nFuturesBytesSink is the adapter of <code>futures::Sink</code> generated …\nFuturesBytesStream is the adapter of <code>Stream</code> generated by …\nFuturesDeleteSink is a sink that generated by <code>Deleter</code>\ngcs: Google Cloud Storage backend.\ngdrive: GoogleDrive services.\nghac: GitHub Action Cache services.\nGithub Contents: Github contents support.\ngridfs: MongoDB Gridfs Services\nhdfs: Hadoop Distributed File System.\nNative HDFS: Hdfs Native service, using rust hdfs-native …\nhttp: HTTP backend.\nhuggingface: Huggingface services.\nicloud: APPLE icloud services.\nIntoDeleteInput is a helper trait that makes it easier for …\nipmfs: IPFS HTTP Gateway\nipmfs: IPFS mutable file system\nThe given path is a directory.\nThe given file paths are same.\nKoofr: Koofr Services.\nlakefs: LakeFS Services\nlibsql: Libsql services\nLister is designed to list entries at given path in an …\nmemcached: Memcached service support.\nmemory: In memory backend support.\nMetadata contains all the information related to a …\nmini-moka: Mini Moka backend support.\nmoka: moka backend support.\nmongodb: MongoDB Services\nmonoiofs: monoio fs services.\nmysql: Mysql services\nNebulaGraph: NebulaGraph Services\nThe given path is not a directory.\nThe given path is not found.\nobs: Huawei Cloud OBS services.\nContains the success value\nonedrive: Microsoft OneDrive services.\nThe <code>Operator</code> serves as the entry point for all public …\nOperatorBuilder is a typed builder to build an Operator.\nMetadata for operator, users can use this metadata to get …\noss: Aliyun Object Storage Services\nPcloud: Pcloud Services.\nThe given path doesn’t have enough permission for this …\npersy: persy backend support.\npostgresql: Postgresql services\nThe range of the content is not satisfied.\nRequests that sent to this path is over the limit, please …\nReader is designed to read data from given path in an …\nredb: Redb Services\nredis: Redis services\nResult that is a wrapper of <code>Result&lt;T, opendal::Error&gt;</code>\nrocksdb: RocksDB services\ns3: AWS S3 alike services.\nAssociated scheme for this builder. It indicates what …\nServices that OpenDAL supports\nSeafile: Seafile Services.\nsftp: SFTP services\nsled: Sled services\nsqlite: Sqlite services\nStdIterator is the adapter of <code>Iterator</code> for <code>BlockingReader</code>.\nStdReader is the adapter of <code>Read</code>, <code>Seek</code> and <code>BufRead</code> for …\nStdWriter is the adapter of <code>std::io::Write</code> for …\nSupabase: Supabase storage service\nsurrealdb: Surrealdb Services\nswift: Swift backend support.\ntikv: Tikv Services\nOpenDAL don’t know what happened here, and no actions …\nUnknown means we don’t know what we can do on this path.\nUnderlying service doesn’t support this operation.\nUpyun: Upyun Services.\nVercel Artifacts: Vercel Artifacts service, as known as …\nVercelBlob: VercelBlob Services.\nwebdav: WebDAV support.\nwebhdfs: WebHDFS RESTful API Services\nWriter is designed to write data into given path in an …\nYandexDisk: YandexDisk Services.\nAbort the writer and clean up all written data.\nCreate a new blocking operator.\nIndicates if blocking operations are supported.\nConsume the accessor builder to build a service.\nCache control of this entry.\nCheck if this operator can work correctly.\nClose the writer and make sure all data have been …\nClose the writer and make sure all data have been …\nClose the internal writer and make sure all data have been …\nClose the deleter, this will flush the deleter and wait …\nClose the deleter, this will flush the deleter and wait …\nContent-Disposition of this entry\nContent Encoding of this entry.\nContent length of this entry.\nContent MD5 of this entry.\nContent Range of this entry.\nContent Type of this entry.\nCopy a file from <code>from</code> to <code>to</code>.\nCopy a file from <code>from</code> to <code>to</code>.\nIndicates if copy operations are supported.\nNumber of <code>Bytes</code> in <code>Buffer</code>.\nCreate a dir at given path.\nCreate a dir at given path.\nIndicates if directory creation is supported.\nGet current <code>Bytes</code>.\nGet the default executor.\nDelete a path.\nDelete a path.\nDelete the given path.\nDelete given path.\nIndicates if delete operations are supported.\nDelete an infallible iterator of paths.\nDelete an infallible iterator of paths.\nDelete an infallible iterator of paths.\nDelete an infallible iterator of paths.\nMaximum size supported for single delete operations.\nDelete an infallible stream of paths.\nDelete an infallible stream of paths.\nDelete an fallible iterator of paths.\nDelete an fallible iterator of paths.\nDelete a fallible iterator of paths.\nDelete a fallible iterator of paths.\nDelete an fallible stream of paths.\nDelete an fallible stream of paths.\nDelete the given path with extra options.\nDelete given path with options.\nIndicates if versions delete operations are supported.\nCreate a <code>Deleter</code> to continuously remove content from …\nCreate a <code>BlockingDeleter</code> to continuously remove content …\nThis module holds documentation for OpenDAL.\nGet all enabled schemes.\nETag of this entry.\nExecute async task in background.\nexecutors module provides implementations for the <code>Execute</code> …\nCheck if this path exists or not.\nCheck if this path exists or not.\nFetch specific ranges from reader.\nFinish the building to construct an Operator.\nFlush the deleter, returns the number of deleted paths.\nFlush the deleter, returns the number of deleted paths.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreate a new operator from given config.\nConvert inner accessor into operator.\nDeserialize from an iterator.\nDeserialize from an iterator.\nCreate a new operator from given iterator in static …\nCreate a new operator from given map.\nGet [<code>Full Capability</code>] of operator.\nGet information of underlying accessor.\nGet information of underlying accessor.\nFetch the internal accessor.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConvert this configuration into a service builder.\nConvert reader into <code>StdBytesIterator</code> which implements …\nConvert writer into <code>FuturesBytesSink</code> which implements …\nConvert reader into <code>FuturesBytesStream</code> which implements …\nConvert <code>self</code> into a <code>DeleteInput</code>.\nConvert reader into <code>FuturesAsyncReader</code> which implements …\nConvert writer into <code>FuturesAsyncWriter</code> which implements …\nConvert operator into inner accessor.\nConsume this entry to get its path and metadata.\nConvert the deleter into a sink.\nConvert self into static str.\nConvert self into static str.\nConvert reader into <code>StdReader</code> which implements …\nConvert writer into <code>StdWriter</code> which implements …\nChecks whether the metadata corresponds to the most recent …\nChecks if the file (or version) associated with this …\nCheck if this mode is DIR.\nReturns <code>true</code> if this metadata is for a directory.\nCheck if buffer is empty.\nCheck if this path exists or not.\nCheck if this path exists or not.\nCheck if this mode is FILE.\nReturns <code>true</code> if this metadata is for a file.\nCheck if this error is temporary.\nReturn error’s kind.\nLast modified of this entry.\nCreate a new layer with static dispatch.\nCreate a new layer with dynamic dispatch.\n<code>Layer</code> is the mechanism to intercept operations.\nGet the length of the buffer.\nGet current operator’s limit. Limit is usually the …\nGet current operator’s limit\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir.\nIndicates if list operations are supported.\nIndicates whether cache control information is available …\nIndicates whether content disposition information is …\nIndicates whether content length information is available …\nIndicates whether content MD5 checksum is available in …\nIndicates whether content range information is available …\nIndicates whether content type information is available in …\nIndicates whether entity tag is available in list response\nIndicates whether last modified timestamp is available in …\nIndicates whether user-defined metadata is available in …\nIndicates whether version information is available in list …\nList entries that starts with given <code>path</code> in parent dir …\nList entries that starts with given <code>path</code> in parent dir. …\nIndicates if listing with deleted files included is …\nIndicates if list operations support result limiting.\nIndicates if recursive listing is supported.\nIndicates if list operations support continuation from a …\nIndicates if versions listing is supported.\nIndicates if listing with versions included is supported.\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir …\nList entries within a given directory as an iterator with …\nOperate on error with map.\nFetch metadata of this entry.\nmode represent this entry’s mode.\nName of entry. Name is the last segment of path.\nName of backend, could be empty if underlying backend doesn…\nGet [<code>Native Capability</code>] of operator.\nCreate a new buffer iterator.\nCreate a new operator builder.\nCreate a new Error with error kind and message.\nCreate a new empty buffer.\nCreate a new metadata\nCreate a default executor.\nCreate a new operator with input builder.\nFunctions provides the functions generated by …\nFutures provides the futures generated by <code>Operator</code>\nPath of entry. Path is relative to operator’s root.\nThe path of the path to delete.\nIndicates if presigned URL generation is supported.\nPresign an operation for read.\nIndicates if presigned URLs for read operations are …\nPresign an operation for read with extra options.\nPresign an operation for stat(head).\nIndicates if presigned URLs for stat operations are …\nPresign an operation for stat(head).\nPresign an operation for write.\nIndicates if presigned URLs for write operations are …\nPresign an operation for write with extra options.\nRaw modules provide raw APIs that used by underlying …\nRead give range from reader into <code>Buffer</code>.\nRead give range from reader into <code>Buffer</code>.\nRead the whole path into a bytes.\nRead the whole path into a bytes.\nIndicates if the operator supports read operations.\nRead all data from reader into given <code>BufMut</code>.\nThis operation will copy and write bytes into given <code>BufMut</code>…\nRead all bytes until EOF.\nRead the whole path into a bytes with extra options.\nRead the whole path into a bytes with extra options.\nIndicates if conditional read operations using If-Match …\nIndicates if conditional read operations using …\nIndicates if conditional read operations using …\nIndicates if conditional read operations using …\nIndicates if Cache-Control header override is supported …\nIndicates if Content-Disposition header override is …\nIndicates if Content-Type header override is supported …\nIndicates if versions read operations are supported.\nCreate a new reader which can read the whole path.\nCreate a new reader which can read the whole path.\nCreate a new reader with extra options\nCreate a new reader with extra options\nNotes\nNotes\nRemove the path and all nested dirs and files recursively.\nRemove the path and all nested dirs and files recursively.\nremove will remove files via the given paths.\nremove will remove files via the given paths.\nRename a file from <code>from</code> to <code>to</code>.\nRename a file from <code>from</code> to <code>to</code>.\nIndicates if rename operations are supported.\nRoot of operator, will be in format like <code>/path/to/dir/</code>\n<code>Scheme</code> of operator.\nServices will provide builders to build underlying …\nSet cache control of this entry.\nSet Content-Disposition of this entry\nSet Content Encoding of this entry.\nSet content length of this entry.\nSet content MD5 of this entry.\nSet Content Range of this entry.\nSet Content Type of this entry.\nSet ETag of this entry.\nSet the <code>is_current</code> status of this entry.\nSet the deleted status of this entry.\nSet Last modified of this entry.\nSet mode for entry.\nSet permanent status for error.\nSet persistent status for error.\nSet source for error.\nSet temporary status for error.\nSet the version of the file\nIndicate if the operator supports shared access.\nReturns a slice of self for the provided range.\nGet given path’s metadata.\nGet given path’s metadata.\nIndicates if the operator supports metadata retrieval …\nIndicates whether cache control information is available …\nIndicates whether content disposition information is …\nIndicates whether content encoding information is …\nIndicates whether content length information is available …\nIndicates whether content MD5 checksum is available in …\nIndicates whether content range information is available …\nIndicates whether content type information is available in …\nIndicates whether entity tag is available in stat response\nIndicates whether last modified timestamp is available in …\nIndicates whether user-defined metadata is available in …\nIndicates whether version information is available in stat …\nGet given path’s metadata with extra options.\nGet given path’s metadata with extra options.\nIndicates if conditional stat operations using If-Match …\nIndicates if conditional stat operations using …\nIndicates if Cache-Control header override is supported …\nIndicates if Content-Disposition header override is …\nIndicates if Content-Type header override is supported …\nIndicates if versions stat operations are supported.\nReturn a future that will be resolved after the given …\nReturn a future that will be resolved after the given …\nCombine all bytes together into one single <code>Bytes</code>.\nConvert buffer into a slice of <code>IoSlice</code> for vectored write.\nCombine all bytes together into one single <code>Vec&lt;u8&gt;</code>.\nShortens the buffer, keeping the first <code>len</code> bytes and …\nUser defined metadata of this entry\nRetrieves the <code>version</code> of the file, if available.\nThe version of the path to delete.\nCreate a new operator via given scheme and iterator of …\nCreate a new operator from given scheme and map.\nCreate a new executor with given execute impl.\nSet cache control of this entry.\nSet Content-Disposition of this entry\nSet content length of this entry.\nSet content MD5 of this entry.\nSet Content Range of this entry.\nSet Content Type of this entry.\nAdd more context in error.\nSpecify the default executor.\nSet ETag of this entry.\nSet the <code>is_current</code> status of this entry.\nSet the deleted status of this entry.\nSet Last modified of this entry.\nSpecify the batch limit.\nSpecify the batch limit.\nSet mode for entry.\nUpdate error’s operation.\nSet user defined metadata of this entry\nWith the version of the file.\nWrite <code>Buffer</code> into writer.\nWrite <code>Buffer</code> into writer.\nWrite bytes into path.\nWrite bytes into given path.\nIndicates if the operator supports write operations.\nIndicates if append operations are supported.\nIndicates if writing empty content is supported.\nIndicates if multiple write operations can be performed on …\nWrite <code>bytes::Buf</code> into inner writer.\nMaximum size supported for multipart uploads. For example, …\nMinimum size required for multipart uploads (except for …\nMaximum total size supported for write operations. For …\nWrite data with extra options.\nWrite data with options.\nIndicates if Cache-Control can be specified during write …\nIndicates if Content-Disposition can be specified during …\nIndicates if Content-Encoding can be specified during …\nIndicates if Content-Type can be specified during write …\nIndicates if conditional write operations using If-Match …\nIndicates if conditional write operations using …\nIndicates if write operations can be conditional on object …\nIndicates if custom user metadata can be attached during …\nCreate a writer for streaming data to the given path.\nWrite multiple bytes into given path.\nCreate a writer for streaming data to the given path with …\nCreate a new reader with extra options\nChanges log for all OpenDAL released versions.\nCompare opendal with other projects to find out the …\nThe core concepts of OpenDAL’s public API.\nThe internal implement details of OpenDAL.\nRFCs - OpenDAL Active RFC List\nUpgrade and migrate procedures while OpenDAL meets …\nOpenDAL vs object_store\nThe internal implementation details of <code>Access</code>.\nThe internal implementation details of <code>Layer</code>.\nRFC example\nObject native API\nError handle\nAuto region\nObject stream\nLimited reader\nPath normalization\nAsync streaming IO\nRemove credential\nCreate dir\nRetryable error\nObject ID\nDir entry\nAccessor capabilities\nPresign\nCommand line interface\nInit from iter\nMultipart\nGateway\nNew builder\nWrite refactor\nList metadata reuse\nBlocking API\nRedis service\nSplit capabilities\nPath in accessor\nGeneric KV services\nObject reader\nRefactor error\nObject handler\nObject metadataer\nQuery based metadata\nObject writer\nRemove object concept\nOperation extension\nWriter sink API\nAppend API\nChain based operator API\nObject versioning\nMerge append into write\nLister API\nList with metakey\nNative capability\nRemove write copy from\nConfig\nAlign list API\nList prefix\nLazy reader\nList recursive\nConcurrent stat in list\nBuffered Reader\nConcurrent Writer\nDeleter API\nRange Based Read API\nExecutor API\nRemove metakey\nOperator from uri\nContext\nConditional Reader\nList With Deleted\nExecutor that uses the <code>tokio::task::spawn</code> to execute …\nTokio’s JoinHandle has its own <code>abort</code> support, so …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nAdd Efficient, logical ‘stack’ traces of async …\nAdd an Instrument await-tree for actor-based applications …\nAdd blocking API support for non-blocking services.\nAdd an extra capability check layer for every operation\nInject chaos into underlying services for robustness test.\nAdd concurrent request limit.\nSupport User Statically-Defined Tracing(aka USDT) on Linux\nAdd fastrace for every operation.\nAdd an immutable in-memory index for underlying storage …\nLoggingInterceptor is used to intercept the log.\nAdd log for every operation.\nAdd metrics for every operation.\nA layer that can automatically set <code>Content-Type</code> based on …\nAdd opentelemetry::trace for every operation.\nAdd prometheus-client for every operation.\n<code>PrometheusClientLayerBuilder</code> is a config builder to build …\nAdd prometheus for every operation.\n<code>PrometheusLayerBuilder</code> is a config builder to build a …\nRetryInterceptor is used to intercept while retry happened.\nAdd retry for temporary failed operations.\nAdd a bandwidth rate limiter to the underlying services.\nAdd timeout for every operation to avoid slow or …\nAdd tracing for every operation.\nCreate a <code>PrometheusLayerBuilder</code> to set the configuration …\nCreate a <code>PrometheusClientLayerBuilder</code> to set the …\nCreate a new <code>BlockingLayer</code> with the current runtime’s …\nInsert keys from iter.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nInsert a key into index.\nEverytime RetryLayer is retrying, this function will be …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nEverytime there is a log, this function will be called.\nCreate a new retry layer.\nCreate a new ConcurrentLimitLayer will specify permits\nCreate the layer with specific logging interceptor.\nCreate a new <code>TimeoutLayer</code> with default settings.\nCreate a new chaos layer with specified error ratio.\nCreate a new <code>ThrottleLayer</code> with given bandwidth and burst.\nCreate a new <code>AwaitTreeLayer</code>.\nOpenDAL Observability Layer\nSet buckets for <code>operation_bytes</code> histogram.\nSet buckets for <code>operation_bytes</code> histogram.\nSet buckets for <code>operation_duration_seconds</code> histogram.\nSet buckets for <code>operation_duration_seconds</code> histogram.\nSet the level of path label.\nSet the level of path label.\nSet the level of path label.\nRegister the metrics into the given registry and return a …\nRegister the metrics into the registry and return a …\nRegister the metrics into the default registry and return …\nSet factor of current backoff.\nSet io timeout for TimeoutLayer with given value.\nSet jitter of current backoff.\nSet max_delay of current backoff.\nSet max_times of current backoff.\nSet min_delay of current backoff.\nSet the retry interceptor as new notify.\nSet speed for TimeoutLayer with given value.\nSet timeout for TimeoutLayer with given value.\nThe metric label for the error kind.\nThe metric label for the namespace like bucket name in s3.\nThe metric label for the operation like read, write, list.\nThe metric label for the path used by request.\nThe metric label for the root path.\nThe metric label for the scheme like s3, fs, cos.\nThe metric metadata for the operation bytes.\nThe metric metadata for the operation duration in seconds.\nThe metric metadata for the operation errors total.\nThe metric metadata which contains the metric name and …\nThe metrics accessor for opendal.\nThe interceptor for metrics.\nThe metrics layer for opendal.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the metric help.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns the metric name.\nReturns the metric name with a given prefix.\nCreate a new metrics layer.\nObserve the operation bytes happened in IO like read and …\nObserve the operation duration in seconds.\nObserve the operation errors total.\nReturn the path label value according to the given <code>path</code> …\nFunction that generated by <code>BlockingOperator::delete_with</code>.\nFunction that generated by <code>BlockingOperator::list_with</code>.\nFunction that generated by <code>BlockingOperator::lister_with</code>.\nFunction that generated by <code>BlockingOperator::read_with</code>.\nFunction that generated by <code>BlockingOperator::reader_with</code>.\nFunction that generated by <code>BlockingOperator::stat_with</code>.\nFunction that generated by <code>BlockingOperator::write_with</code>.\nFunction that generated by <code>BlockingOperator::writer_with</code>.\nSet the append mode of op.\nSet the append mode of op.\nSet the chunk size of op.\nSet the content type of option\nSet the content type of option\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nSet the chunk size of op.\nSet the chunk size of op.\nSet the content disposition of option\nSet the content disposition of option\nSet the content type of option\nSet the content type of option\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nSet the If-Match for this operation.\nSet the If-Match for this operation.\nSet the If-None-Match for this operation.\nSet the If-None-Match for this operation.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe limit passed to underlying service to specify the max …\nThe limit passed to underlying service to specify the max …\nSets the cache-control header that should be send back by …\nSets the content-disposition header that should be send …\nSets the content-type header that should be send back by …\nSet the range for this operation.\nThe recursive is used to control whether the list …\nThe recursive is used to control whether the list …\nThe start_after passes to underlying service to specify …\nThe start_after passes to underlying service to specify …\nSet the version for this operation.\nSet the version for this operation.\nSet the version for this operation.\nFuture that generated by <code>Operator::delete_with</code>.\nFuture that generated by [<code>Operator::deleter_with</code>].\nFuture that generated by <code>Operator::list_with</code> or …\nFuture that generated by <code>Operator::list_with</code> or …\nFuture that generated by <code>Operator::presign_read_with</code>.\nFuture that generated by <code>Operator::presign_stat_with</code>.\nFuture that generated by <code>Operator::presign_write_with</code>.\nFuture that generated by <code>Operator::read_with</code>.\nFuture that generated by <code>Operator::read_with</code> or …\nFuture that generated by <code>Operator::stat_with</code>.\nFuture that generated by <code>Operator::write_with</code>.\nFuture that generated by <code>Operator::writer_with</code>.\nOperatorFuture is the future generated by <code>Operator</code>.\nSets append mode for this write request.\nSets append mode for this write request.\nSets append mode for this write request.\nSets append mode for this write request.\nSets Cache-Control header for this write operation.\nSet the content type of option\nSets Cache-Control header for this write operation.\nSet the content type of option\nSets Cache-Control header for this write operation.\nSets Cache-Control header for this write operation.\nSets chunk size for buffered writes.\nSets chunk size for buffered writes.\nOpenDAL will use services’ preferred chunk size by …\nOpenDAL will use services’ preferred chunk size by …\nOpenDAL will use services’ preferred chunk size by …\nOpenDAL will use services’ preferred chunk size by …\nSets chunk size for buffered writes.\nSets chunk size for buffered writes.\nSet <code>concurrent</code> for the reader.\nSet <code>concurrent</code> for the reader.\nSets concurrent write operations for this writer.\nSets concurrent write operations for this writer.\nSet <code>concurrent</code> for the reader.\nSet <code>concurrent</code> for the reader.\nSets concurrent write operations for this writer.\nSets concurrent write operations for this writer.\nSet the content disposition of option\n<code>content_disposition</code>\n<code>content_disposition</code>\nSet the content disposition of option\n<code>content_disposition</code>\n<code>content_disposition</code>\nSets Content-Encoding header for this write request.\nSets Content-Encoding header for this write request.\nSets Content-Encoding header for this write request.\nSets Content-Encoding header for this write request.\nSets <code>Content-Type</code> header for this write operation.\nSet the content type of option\nSets <code>Content-Type</code> header for this write operation.\nSet the content type of option\nSets <code>Content-Type</code> header for this write operation.\nSets <code>Content-Type</code> header for this write operation.\nControls whether the <code>list</code> operation should include deleted …\nControls whether the <code>list</code> operation should include deleted …\nControls whether the <code>list</code> operation should include deleted …\nControls whether the <code>list</code> operation should include deleted …\nSet the executor for this operation.\nSet the executor for this operation.\nSet the executor for this operation.\nSet the executor for this operation.\nSet the executor for this operation.\nSet the executor for this operation.\nReturns the argument unchanged.\nControls the optimization strategy for range reads in …\nControls the optimization strategy for range reads in …\nSets If-Match header for this write request.\nSet the If-Match of the option\nSet the If-Match of the option\nSet <code>if_match</code> for this <code>read</code> request.\nSets If-Match header for this write request.\nSet the If-Match for this operation.\nSet <code>if-match</code> for this <code>read</code> request.\nSet the If-Match for this operation.\nSet the If-Match of the option\nSet the If-Match of the option\nSet <code>if_match</code> for this <code>read</code> request.\nSet <code>if-match</code> for this <code>read</code> request.\nSets If-Match header for this write request.\nSets If-Match header for this write request.\nSet <code>if-modified-since</code> for this <code>read</code> request.\n<code>if_modified_since</code>\n<code>if_modified_since</code>\nSet <code>if-modified-since</code> for this <code>read</code> request.\nSet the If-None-Match for this operation.\nSets If-None-Match header for this write request.\nSet the If-None-Match of the option\nSet the If-None-Match of the option\nSets If-None-Match header for this write request.\nSet <code>if-none-match</code> for this <code>read</code> request.\nSet <code>if_none_match</code> for this <code>read</code> request.\nSet the If-None-Match for this operation.\nSet the If-None-Match of the option\nSet the If-None-Match of the option\nSet <code>if_none_match</code> for this <code>read</code> request.\nSet <code>if-none-match</code> for this <code>read</code> request.\nSets If-None-Match header for this write request.\nSets If-None-Match header for this write request.\nSets the condition that write operation will succeed only …\nSets the condition that write operation will succeed only …\nSets the condition that write operation will succeed only …\nSets the condition that write operation will succeed only …\nSet <code>if_unmodified_since</code> for this <code>read</code> request.\nSet <code>if-unmodified-since</code> for this <code>read</code> request.\nSet <code>if_unmodified_since</code> for this <code>read</code> request.\nSet <code>if-unmodified-since</code> for this <code>read</code> request.\nCalls <code>U::from(self)</code>.\nThe limit passed to underlying service to specify the max …\nThe limit passed to underlying service to specify the max …\nThe limit passed to underlying service to specify the max …\nThe limit passed to underlying service to specify the max …\nSets the cache-control header that should be sent back by …\nSets the cache-control header that should be sent back by …\nSets the cache-control header that should be sent back by …\nSets the cache-control header that should be sent back by …\nSets the content-disposition header that should be sent …\nSets the content-disposition header that should be sent …\nSets the content-disposition header that should be sent …\nSets the content-disposition header that should be sent …\nSets the content-type header that should be sent back by …\nSets the content-type header that should be sent back by …\nSets the content-type header that should be sent back by …\nSets the content-type header that should be sent back by …\nSet <code>range</code> for this <code>read</code> request.\nSet <code>range</code> for this <code>read</code> request.\nThe recursive is used to control whether the list …\nThe recursive is used to control whether the list …\nThe recursive is used to control whether the list …\nThe recursive is used to control whether the list …\nThe start_after passes to underlying service to specify …\nThe start_after passes to underlying service to specify …\nThe start_after passes to underlying service to specify …\nThe start_after passes to underlying service to specify …\nSets user metadata for this write request.\nSets user metadata for this write request.\nSets user metadata for this write request.\nSets user metadata for this write request.\nThe version is used to control whether the object versions …\nSet <code>version</code> for this <code>reader</code>.\nChange the version of this delete operation.\nSet the version for this operation.\nThe version is used to control whether the object versions …\nSet <code>version</code> for this <code>read</code> request.\nSet the version for this operation.\nSet <code>version</code> for this <code>read</code> request.\nSet <code>version</code> for this <code>reader</code>.\nChange the version of this delete operation.\nThe version is used to control whether the object versions …\nThe version is used to control whether the object versions …\nControls whether the <code>list</code> operation should return file …\nControls whether the <code>list</code> operation should return file …\nControls whether the <code>list</code> operation should return file …\nControls whether the <code>list</code> operation should return file …\nUnderlying trait of all backends for implementers.\n<code>AccessDyn</code> is the dyn version of <code>Access</code> make it possible to …\nAccessor is the type erased accessor with <code>Arc&lt;dyn Accessor&gt;</code>…\nMetadata for accessor, users can use this metadata to get …\nAtomicContentLength is a wrapper of AtomicU64 that used to …\nOperation for <code>crate::raw::Access::blocking_copy</code>\nOperation for <code>crate::raw::Access::blocking_create_dir</code>\nOperation for <code>crate::raw::Access::blocking_delete</code>\nBlockingDeleter is the associated deleter returned …\nOperation for <code>crate::raw::oio::BlockingDelete::delete</code>\nOperation for <code>crate::raw::oio::BlockingDelete::flush</code>\nOperation for <code>crate::raw::Access::blocking_list</code>\nBlockingLister is the associated lister returned …\nOperation for <code>crate::raw::oio::BlockingList::next</code>\nOperation for <code>crate::raw::Access::blocking_read</code>\nBlockingReader is the associated reader returned …\nOperation for <code>crate::raw::oio::BlockingRead::read</code>\nOperation for <code>crate::raw::Access::blocking_rename</code>\nOperation for <code>crate::raw::Access::blocking_stat</code>\nOperation for <code>crate::raw::Access::blocking_write</code>\nBlockingWriter is the associated writer returned …\nOperation for <code>crate::raw::oio::BlockingWrite::close</code>\nOperation for <code>crate::raw::oio::BlockingWrite::write</code>\nBoxedFuture is the type alias of <code>futures::future::BoxFuture</code>…\nBoxedStaticFuture is the type alias of …\nBytesContentRange is the content range of bytes.\nBytesRange(offset, size) carries a range of content.\nConcurrentFutures is a stream that can hold a stream of …\nConcurrentTasks is used to execute tasks concurrently.\nConfigDeserializer is used to deserialize given configs …\nOperation for <code>crate::raw::Access::copy</code>\nOperation for <code>crate::raw::Access::create_dir</code>\nOperation for <code>crate::raw::Access::delete</code>\nDeleter is the associated deleter returned in <code>delete</code> …\nOperation for <code>crate::raw::oio::Delete::delete</code>\nOperation for <code>crate::raw::oio::Delete::flush</code>\nFormDataPart is a builder for multipart/form-data part.\nThe fourth type for the <code>FourWays</code>.\nFourWays is used to implement traits that based on four …\nHttpBody is the streaming body that opendal’s HttpClient …\nHttpClient that used across opendal.\nHttpFetch is the trait to fetch a request in async way. …\nOperation for <code>crate::raw::Access::info</code>\nLayer is used to intercept the operations on the …\nLayeredAccess is layered accessor that forward all not …\nThe layered accessor that returned by this layer.\nOperation for <code>crate::raw::Access::list</code>\nLister is the associated lister returned in <code>list</code> operation.\nOperation for <code>crate::raw::oio::List::next</code>\nMaybeSend is a marker to determine whether a type is <code>Send</code> …\nMixedPart is a builder for multipart/mixed part.\nMultipart is a builder for multipart/form-data.\nThe first type for the <code>TwoWays</code>.\nThe first type for the <code>ThreeWays</code>.\nThe first type for the <code>FourWays</code>.\nArgs for <code>copy</code> operation.\nArgs for <code>create</code> operation.\nArgs for <code>delete</code> operation.\nArgs for <code>delete</code> operation.\nArgs for <code>list</code> operation.\nArgs for <code>presign</code> operation.\nArgs for <code>read</code> operation.\nArgs for reader operation.\nArgs for <code>rename</code> operation.\nArgs for <code>stat</code> operation.\nArgs for <code>write</code> operation.\nArgs for <code>writer</code> operation.\nOperation is the name for APIs in <code>Accessor</code>.\nPart is a trait for multipart part.\nPathCacher is a cache for path query.\nThe trait required for path cacher.\nOperation for <code>crate::raw::Access::presign</code>\nPresign operation used for presign.\nPresignedRequest is a presigned request return by <code>presign</code>.\nOperation for <code>crate::raw::Access::read</code>\nPresign a read operation.\nReader is the associated reader returned in <code>read</code> operation.\nOperation for <code>crate::raw::oio::Read::read</code>\nOperation for <code>crate::raw::Access::rename</code>\nReply for <code>copy</code> operation.\nReply for <code>create_dir</code> operation\nReply for <code>delete</code> operation\nReply for <code>list</code> operation.\nReply for <code>presign</code> operation.\nReply for <code>read</code> operation.\nReply for <code>rename</code> operation.\nReply for <code>stat</code> operation.\nReply for <code>write</code> operation.\nOperation for <code>crate::raw::Access::stat</code>\nPresign a stat(head) operation.\nTYPE is the type of multipart.\nThe third type for the <code>ThreeWays</code>.\nThe third type for the <code>FourWays</code>.\nThreeWays is used to implement traits that based on three …\nThe second type for the <code>TwoWays</code>.\nThe second type for the <code>ThreeWays</code>.\nThe second type for the <code>FourWays</code>.\nTwoWays is used to implement traits that based on two ways.\nVERSION is the compiled version of OpenDAL.\nOperation for <code>crate::raw::Access::write</code>\nPresign a write operation.\nWriter is the associated writer returned in <code>write</code> …\nOperation for <code>crate::raw::oio::Write::abort</code>\nOperation for <code>crate::raw::oio::Write::close</code>\nOperation for <code>crate::raw::oio::Write::write</code>\nProviding adapters and its implementations.\nAdvance the range by <code>n</code> bytes.\nGet the append from op.\nConsume the input and generate a request with multipart …\nInvoke the <code>blocking_copy</code> operation on the specified <code>from</code> …\nInvoke the <code>blocking_copy</code> operation on the specified <code>from</code> …\nDyn version of <code>Accessor::blocking_copy</code>\nInvoke the <code>blocking_create</code> operation on the specified path.\nInvoke the <code>blocking_create</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_create_dir</code>\nInvoke the <code>blocking_delete</code> operation on the specified path.\nInvoke the <code>blocking_delete</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_delete</code>\nInvoke the <code>blocking_list</code> operation on the specified path.\nInvoke the <code>blocking_list</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_list</code>\nInvoke the <code>blocking_read</code> operation on the specified path.\nInvoke the <code>blocking_read</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_read</code>\nInvoke the <code>blocking_rename</code> operation on the specified <code>from</code> …\nInvoke the <code>blocking_rename</code> operation on the specified <code>from</code> …\nDyn version of <code>Accessor::blocking_rename</code>\nInvoke the <code>blocking_stat</code> operation on the specified path.\nInvoke the <code>blocking_stat</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_stat</code>\nInvoke the <code>blocking_write</code> operation on the specified path.\nInvoke the <code>blocking_write</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_write</code>\nBuild a new http client in async context.\nbuild_abs_path will build an absolute path with root.\nBuild header value from given string.\nbuild_rel_path will build a relative path towards root.\nbuild_rooted_abs_path will build an absolute path with …\nGet the cache control from option\nGet chunk from option\nGet the chunk from op.\nClear all tasks and results.\nDrop all tasks.\nGet the concurrent of list operation.\nGet concurrent from option\nGet the concurrent.\nSet the content for this part.\nSet the content for this part.\nGet the content disposition from option\nGet the content encoding from option\nGet the content type from option\nInvoke the <code>copy</code> operation on the specified <code>from</code> path and <code>to</code>…\nInvoke the <code>copy</code> operation on the specified <code>from</code> path and <code>to</code>…\nDyn version of <code>Accessor::copy</code>\nCreate a dir by parent_id and name.\nInvoke the <code>create</code> operation on the specified path\nInvoke the <code>create</code> operation on the specified path\nDyn version of <code>Accessor::create_dir</code>\nInvoke the <code>delete</code> operation on the specified path.\nInvoke the <code>delete</code> operation on the specified path.\nDyn version of <code>Accessor::delete</code>\nGet the deleted of this list operation\nEnsure input dir exists.\nExecute the task with given input.\nGet executor from option\nGet the executor from option\nGet expire from op.\nFetch a request in async way.\nFetch a request in async way.\nformat will generates the bytes.\nformat authorization header by basic auth.\nformat authorization header by bearer token.\nformat content md5 header by given input.\nformat datetime into http date, this format is required by:\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nBuild a mixed part from a request.\nGet service’s full capabilities.\nGet service’s full capabilities.\nGet gap from option\nGet the id for the given path.\nGet basename from path.\nGet parent from path.\nCheck if there are remaining space to push new tasks.\nReturn true if there is remaining space to push new …\nChunk if there are remaining results to fetch.\nInsert a header into part.\nInsert a header into part.\nReturn request’s header.\nGet If-Match from option\nGet If-Match from option\nGet If-Match from option\nGet If-Modified-Since from option\nGet If-None-Match from option\nGet If-None-Match from option\nGet If-None-Match from option\nGet If-Not-Exist from option\nGet If-Unmodified-Since from option\nInvoke the <code>info</code> operation to get metadata of accessor.\nDyn version of <code>Accessor::info</code>\nInsert a new cache entry.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConsume RpStat to get the inner metadata.\nConsume OpPresign into (Duration, PresignOperation)\nInto parts.\nConsume reply to build a presigned request.\nConsume a mixed part to build a response.\nConvert self into static str.\nReturn true if there is no futures in the queue.\nCheck if this range is full of this content.\nCheck if given operation is oneshot or not.\nIntercept the operations on the underlying storage.\nReturn the length of current concurrent futures (both …\nGet the length that specified by this BytesContentRange, …\nGet the limit of list operation.\nInvoke the <code>list</code> operation on the specified path.\nInvoke the <code>list</code> operation on the specified path.\nDyn version of <code>Accessor::list</code>\nLoad content length from AtomicU64.\nOperate on inner metadata.\nSet the method for request in this part.\nReturn request’s method.\nName of backend, could be empty if underlying backend doesn…\nGet backend’s native capabilities.\nCreate a new path cacher.\nCreate a new <code>HttpBody</code> with given stream and optional size.\nCreate a new part builder\nCreate a new mixed part with given uri.\nCreate a new config deserializer.\nCreate a new concurrent tasks with given executor, …\nCreate a new ConcurrentFutures by specifying the number of …\nCreate a new reply for <code>presign</code>.\nCreate a new PresignedRequest\nCreate a new reply for <code>read</code>.\nCreate a new reply for <code>stat</code>.\nCreate a new reply for <code>write</code>.\nCreate a new reply for <code>copy</code>.\nCreate a new reply for <code>rename</code>.\nCreate a new <code>OpCreateDir</code>.\nCreate a new <code>OpDelete</code>.\nCreate a new <code>OpDelete</code>.\nCreate a new <code>OpList</code>.\nCreate a new <code>OpPresign</code>.\nCreate a default <code>OpRead</code> which will read whole content of …\nCreate a new <code>OpReader</code>.\nCreate a new <code>OpStat</code>.\nCreate a new <code>OpWrite</code>.\nCreate a new <code>OpWriter</code>.\nCreate a new <code>OpCopy</code>.\nCreate a new <code>OpMove</code>.\nCreate a new http client in async context.\nCreate a new <code>BytesRange</code>\nCreate a new multipart with random boundary.\nCreate a new AtomicContentLength.\nParse json deserialize error into opendal::Error.\nParse json serialize error into opendal::Error.\nCreate a new error happened during building request.\nCreate a new error happened during signing request.\nCreate a new error happened during signing request.\nParse std io error into opendal::Error.\nParse tokio error into opendal::Error.\nParse xml deserialize error into opendal::Error.\nFetch the successful result from the result queue.\nMake sure all operation are constructed by normalized path:\nMake sure root is normalized to style like <code>/abc/def/</code>.\nGet offset of BytesRange.\n<code>oio</code> provides OpenDAL’s raw traits and types that opendal …\nGet operation from op.\nReturns the cache-control header that should be sent back …\nReturns the cache-control header that should be sent back …\nReturns the content-disposition header that should be sent …\nReturns the content-disposition header that should be sent …\nReturns the content-type header that should be sent back …\nReturns the content-type header that should be sent back …\nparse will parse the bytes into a part.\nTODO\nParse a response with multipart body into Multipart.\nParse Content-Disposition for header map\nParse content encoding from header map.\nParse content length from header map.\nParse content md5 from header map.\nParse content range from header map.\nParse content type from header map.\nparse datetime from given timestamp\nparse datetime from given timestamp_millis\nParse datetime from rfc2822.\nParse datetime from rfc3339.\nParse etag from header map.\nParse header value to string according to name.\nparse_into_metadata will parse standards http headers into …\nParse last modified from header map.\nParse redirect location from header map\nParse multipart boundary from header map.\nParse prefixed headers and return a map with the prefix of …\nInsert a part into multipart.\nInsert a part header into part.\npercent_decode_path will do percent decoding for http …\npercent_encode_path will do percent encoding for http …\nInvoke the <code>presign</code> operation on the specified path.\nInvoke the <code>presign</code> operation on the specified path.\nDyn version of <code>Accessor::presign</code>\nPush new future into the end of queue.\nPush new future into the start of queue, this task will be …\nQuery the id by parent_id and name.\nGot the range of the reader returned by this read …\nGet range from option\nGet the range inclusive of this BytesContentRange, return …\nGet the range inclusive of this BytesContentRange, return …\nInvoke the <code>read</code> operation on the specified path, returns a …\nInvoke the <code>read</code> operation on the specified path, returns a …\nDyn version of <code>Accessor::read</code>\nGet the current recursive.\nReturn the number of remaining space to push new futures.\nRemove a cache entry.\nInvoke the <code>rename</code> operation on the specified <code>from</code> path and …\nInvoke the <code>rename</code> operation on the specified <code>from</code> path and …\nDyn version of <code>Accessor::rename</code>\nFetch the id for the root of the service.\nRoot of backend, will be in format like <code>/path/to/dir/</code>\n<code>Scheme</code> of backend.\nSend a request in async way.\nSet name of this backend.\nSet native capabilities for service.\nSet root for backend.\nSet <code>Scheme</code> for backend.\nGot the size of the reader returned by this read operation.\nGet size of BytesRange.\nGet the size of this BytesContentRange, return <code>None</code> if …\nGet the start_after of list operation.\nInvoke the <code>stat</code> operation on the specified path.\nInvoke the <code>stat</code> operation on the specified path.\nDyn version of <code>Accessor::stat</code>\nStore content length to AtomicU64.\nUtilities for opendal testing.\nRead all data from the stream.\nConvert bytes range into Range header.\nConvert bytes content range into Content-Range header.\nConvert bytes range into rust range.\nReturn request’s uri.\nGet the user defined metadata from the op\nValidate given path is match with given EntryMode.\nSet the version for request in this part.\nGet the version of this delete operation.\nGet the version of this list operation\nGet version from option\nGet version from option\nGet the version of this list operation\nConstruct <code>Self</code> with given <code>reqwest::Client</code>\nSet the append mode of op.\nSet the boundary with given string.\nSet the content type of option\nSet the chunk of the option\nSet the chunk of op.\nChange the concurrent of this list operation.\nSet the concurrent of the option\nSet the maximum concurrent write task amount.\nSet the content disposition of option\nSet the content encoding of option\nSet the content type of option\nChange the deleted of this list operation\nAdd response context to error.\nSet the executor of the option\nSet the executor of the option\nSet the gap of the option\nSet the If-Match of the option\nSet the If-Match of the option\nSet the If-Match of the option\nSet the If-Modified-Since of the option\nSet the If-None-Match of the option\nSet the If-None-Match of the option\nSet the If-None-Match of the option\nSet the If-Not-Exist of the option\nSet the If-Unmodified-Since of the option\nChange the limit of this list operation.\nEnable the lock for the path cacher.\nSets the cache-control header that should be sent back by …\nSets the cache-control header that should be sent back by …\nSets the content-disposition header that should be sent …\nSets the content-disposition header that should be sent …\nSets the content-type header that should be sent back by …\nSets the content-type header that should be sent back by …\nSet the range of the reader returned by this read …\nSet the range of the option\nUpdate BytesContentRange with range.\nThe recursive is used to control whether the list …\nSet the size of the reader returned by this read operation.\nUpdate BytesContentRange with size.\nChange the start_after of this list operation.\nSet the user defined metadata of the op\nChange the version of this delete operation.\nChange the version of this list operation\nSet the version of the option\nSet the version of the option\nChange the version of this list operation\nInvoke the <code>write</code> operation on the specified path, returns a\nInvoke the <code>write</code> operation on the specified path, returns a\nDyn version of <code>Accessor::write</code>\nProviding Key Value Adapter for OpenDAL.\nProviding Typed Key Value Adapter for OpenDAL.\nKvAdapter is the adapter to underlying kv services.\nBackend of kv service. If the storage service is one …\nInfo for this key value accessor.\nScan is the async iterator returned by <code>Adapter::scan</code>.\nA type-erased wrapper of Scan\nTODO: use default associate type <code>= ()</code> after stabilized\nAppend a key into service\nAppend a key into service\nAppend a key into service in blocking way.\nAppend a key into service in blocking way.\nDelete a key from service in blocking way.\nDelete a key from service in blocking way.\nThe blocking version of get.\nThe blocking version of get.\nScan a key prefix to get all keys that start with this key …\nScan a key prefix to get all keys that start with this key …\nThe blocking version of set.\nThe blocking version of set.\nGet the capabilities.\nDelete a key from service.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a key from service.\nReturn the info of this key value accessor.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nGet the name.\nCreate a new KeyValueAccessorInfo.\nCreate a new kv backend.\nFetch the next key in the current key prefix\nScan a key prefix to get all keys that start with this key.\nScan a key prefix to get all keys that start with this key.\nGet the scheme.\nSet a key into service.\nConfigure root within this backend.\nAdapter is the typed adapter to underlying kv services.\nThe typed kv backend which implements Accessor for typed …\nCapability is used to describe what operations are …\nInfo for this key value accessor.\nValue is the typed value stored in adapter.\nDelete a value from adapter.\nGet a value from adapter.\nScan a key prefix to get all keys that start with this key …\nScan a key prefix to get all keys that start with this key …\nSet a value into adapter.\nGet the capabilities.\nDelete a value from adapter.\nIf typed_kv operator supports delete natively.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a value from adapter.\nIf typed_kv operator supports get natively.\nReturn the info of this key value accessor.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMetadata of this value.\nGet the name.\nCreate a new KeyValueAccessorInfo.\nCreate a new kv backend.\nCreate a new dir of value.\nScan a key prefix to get all keys that start with this key.\nScan a key prefix to get all keys that start with this key.\nIf typed_kv operator supports scan natively.\nGet the scheme.\nSet a value into adapter.\nIf typed_kv operator supports set natively.\nIf typed_kv operator supports shared access.\nSize returns the in-memory size of Value.\nThe corresponding content of this value.\nConfigure root within this backend.\nAppendWrite is used to implement <code>oio::Write</code> based on append\nAppendWriter will implements <code>oio::Write</code> based on append …\nBatchDelete is used to implement <code>oio::Delete</code> based on …\nBatchDeleteResult is the result of batch delete operation.\nBatchDeleter is used to implement <code>oio::Delete</code> based on …\nBlockWrite is used to implement <code>oio::Write</code> based on block …\nBlockWriter will implements <code>oio::Write</code> based on block …\nBlockingDelete is the trait to perform delete operations.\nBlockingDeleter is a type erased <code>BlockingDelete</code>\nBlockingList is the blocking version of <code>List</code>.\nBlockingLister is a boxed <code>BlockingList</code>\nBlockingOneShotDelete is used to implement …\nRead is the trait that OpenDAL returns to callers.\nBlockingReader is a arc dyn <code>BlockingRead</code>.\nBlockingWrite is the trait that OpenDAL returns to callers.\nBlockingWriter is a type erased <code>BlockingWrite</code>\nThe Delete trait defines interfaces for performing …\nThe dyn version of <code>Delete</code>\nDeleter is a type erased <code>Delete</code>\nEntry is returned by <code>Page</code> or <code>BlockingPage</code> during list …\nFlatLister will walk dir in bottom up way:\nFlexBuf is a buffer that support frozen bytes and reuse …\nToHierarchyLister will convert a flat list to hierarchy by …\nPage trait is used by <code>raw::Accessor</code> to implement <code>list</code> …\nThe boxed version of <code>List</code>\nThe result of <code>MultipartWrite::write_part</code>.\nMultipartWrite is used to implement <code>oio::Write</code> based on …\nMultipartWriter will implements <code>oio::Write</code> based on …\nOneShotDelete is used to implement <code>oio::Delete</code> based on …\nOneShotDelete is used to implement <code>oio::Delete</code> based on …\nOneShotWrite is used to implement <code>oio::Write</code> based on one …\nOneShotWrite is used to implement <code>oio::Write</code> based on one …\nPageContext is the context passing between <code>PageList</code>.\nPageList is used to implement <code>oio::List</code> based on API …\nPageLister implements <code>oio::List</code> based on <code>PageList</code>.\nPooledBuf is a buffer pool that designed for reusing …\nPositionWrite is used to implement <code>oio::Write</code> based on …\nPositionWriter will implements <code>oio::Write</code> based on …\nPrefixLister is used to filter entries by prefix.\nQueueBuf is a queue of <code>Buffer</code>.\nRead is the internal trait used by OpenDAL to read data …\nReadDyn is the dyn version of <code>Read</code> make it possible to use …\nReader is a type erased <code>Read</code>.\nWrite is the trait that OpenDAL returns to callers.\nWriter is a type erased <code>Write</code>\nAbort the pending writer.\nabort is used to abort the underlying abort.\nabort_block will cancel the block upload and purge all …\nabort_part will cancel the multipart upload and purge all …\nPanics\nAdvance the buffer queue by <code>cnt</code> bytes.\nAppend the data to the end of this object.\ndelete_once delete one path at once.\nThe checksum of the part.\nCleanup the buffer, reset to the initial state.\nClear the buffer queue.\nClose the writer and make sure all data has been flushed.\nClose the writer and make sure all data has been flushed.\nclose is used to close the underlying file.\nBuild a new <code>Buffer</code> from the queue.\ncomplete_block will complete the block upload to build the …\ncomplete_part will complete the multipart upload to build …\nRequests deletion of a resource at the specified path with …\nDelete given path with optional arguments.\ndelete_batch delete multiple paths at once.\nThe dyn version of <code>Delete::delete</code>\ndelete_once delete one path at once.\ndelete_once delete one path at once.\ndone is used to indicate whether the list operation is …\nentries are used to store entries fetched from underlying …\nThe etag of the part.\nCollection of failed deletions, containing tuples of …\nFlushes the deletion queue to ensure queued deletions are …\nFlushes the deletion queue to ensure queued deletions are …\nThe dyn version of <code>Delete::flush</code>\nFreeze the buffer no matter it’s full or not.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet the frozen buffer.\nGet a <code>BytesMut</code> from the pool.\ninitiate_part will call start a multipart upload and …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nIs the buffer queue empty.\nTotal bytes size inside the buffer queue.\nGet entry’s mode.\nCreate a new batch deleter.\nCreate a new one shot deleter.\nCreate a new MultipartWriter.\nCreate a new AppendWriter.\nCreate a new one shot writer.\nCreate a new BlockWriter.\nCreate a new PositionWriter.\nCreate a new PageLister.\nCreate a new flat lister\nCreate a new hierarchy lister\nCreate a new flat lister\nInitializes a new <code>FlexBuf</code> with the given capacity.\nCreate a new buffer pool with a given size.\nCreate a new entry by its corresponding underlying storage.\nCreate a new buffer queue.\nFetch a new page of <code>Entry</code>\nFetch a new page of <code>Entry</code>\nnext_page is used to fetch next page of entries from …\nGet the current offset of the append object.\nThe number of the part, starting from 0.\nGet the path of entry.\nPush new <code>Buffer</code> into the queue.\nPut slice into flex buf.\nPut a <code>BytesMut</code> back to the pool.\nRead at the given offset with the given size.\nRead data from the reader at the given offset with the …\nRead all data from the reader.\nRead all data from the reader.\nThe dyn version of <code>Read::read_all</code>\nThe dyn version of <code>Read::read</code>.\nSet mode for entry.\nSet path for entry.\nCollection of successful deletions, containing tuples of …\nTake the entire buffer queue and leave <code>self</code> in empty …\ntoken is used by underlying storage services to fetch next …\nCreate a new entry with given value.\nSet the initial capacity of the buffer.\nWrite given bytes into writer.\nWrite whole content at once.\nwrite_all_at is used to write the data to underlying …\nwrite_block will write a block of the data.\nwrite_once is used to write the data to underlying storage …\nwrite_once write all data at once.\nwrite_once is used to write the data to underlying storage …\nwrite_part will write a part of the data and returns the …\nRead represents a read action with given input buf size.\nReadAction represents a read action.\nReadChecker is used to check the correctness of the read …\nTEST_RUNTIME is the runtime used for running tests.\nWrite represents a write action with given input buf size.\nWriteAction represents a read action.\nWriteAction is used to check the correctness of the write …\nCheck will check the correctness of the read process via …\nCheck will check the correctness of the read process via …\nCheck the correctness of the write process.\nGet the check’s chunks.\nReturn the raw data of this read checker.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nInit a service with given scheme.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a new read checker by given size and range.\nCreate a new WriteChecker with given size.\nCapabilities\nConfig for Aliyun Drive services support.\nAlluxio services support.\nConfig for alluxio services support.\nCapabilities\nConfig for Atomicserver services support\nCapabilities\nAzure Storage Blob services support.\nAzure Data Lake Storage Gen2 Support. As known as <code>abfs</code>, …\nAzure Data Lake Storage Gen2 Support.\nAzure File services support.\nAzure File services support.\nb2 services support.\nConfig for backblaze b2 services support.\ncacache service support.\ncacache service support.\nchainsafe services support.\nConfig for Chainsafe services support.\nCapabilities\nCloudflare KV Service Support.\n<code>compio</code>-based file system support.\ncompio-based file system support.\nTencent-Cloud COS services support.\nTencent-Cloud COS services support.\nCapabilities\nConfig for Cloudflare D1 backend support.\ndashmap backend support.\ndashmap backend support.\nDbfs’s REST API support. This service will visit the …\nDbfs’s REST API support.\nDropbox backend support.\nConfig for Dropbox backend support.\nEtcd services support.\nConfig for Etcd services support.\nCapabilities\nfoundationdb service support. Config for FoundationDB.\nPOSIX file system support.\nconfig for file system\nFTP and FTPS services support.\nConfig for Ftp services support.\nGoogle Cloud Storage services support.\nGoogle Cloud Storage services support.\nGoogleDrive backend support.\nGoogleDrive configuration.\nGitHub Action Cache Services support.\nConfig for GitHub Action Cache Services support.\ngithub contents services support.\nConfig for GitHub services support.\nCapabilities\nConfig for Grid file system support.\nA distributed file system that provides high-throughput …\nHadoop Distributed File System (HDFS™) support.\nA distributed file system that provides high-throughput …\nConfig for HdfsNative services support.\nHTTP Read-only service support like Nginx and Caddy.\nConfig for Http service support.\nHuggingface’s API support. This service will visit the …\nConfiguration for Huggingface service support.\nIcloudDrive service support.\nConfig for icloud services support.\nIPFS file system support based on IPFS HTTP Gateway.\nConfig for IPFS file system support.\nIPFS file system support based on IPFS MFS API.\nConfig for IPFS MFS support.\nKoofr services support.\nConfig for Koofr services support.\nLakefs’s API support. This service will visit the Lakefs …\nConfiguration for Lakefs service support.\nCapabilities\nConfig for Libsql services support.\nMemcached service support.\nConfig for MemCached services support\nIn memory service support. (BTreeMap Based)\nConfig for memory.\nmini-moka backend support.\nConfig for mini-moka support.\nmoka backend support.\nConfig for Moka services support.\nCapabilities\nConfig for Mongodb service support.\nFile system support via <code>monoio</code>.\nConfig for monoiofs services support.\nCapabilities\nConfig for Mysql services support.\nCapabilities\nConfig for Mysql services support.\nHuawei-Cloud Object Storage Service (OBS) support\nConfig for Huawei-Cloud Object Storage Service (OBS) …\nOneDrive backend support.\nConfig for OneDrive backend support.\nAliyun Object Storage Service (OSS) support\nConfig for Aliyun Object Storage Service (OSS) support.\npCloud services support.\nConfig for Pcloud services support.\npersy service support.\nConfig for persy service support.\nPostgreSQL services support.\nConfig for PostgreSQL services support.\nRedb service support.\nConfig for redb service support.\nRedis services support.\nConfig for Redis services support.\nRocksDB service support.\nConfig for Rocksdb Service.\nAws S3 and compatible services (including minio, …\nConfig for Aws S3 and compatible services (including …\nseafile services support.\nConfig for seafile services support.\nSFTP services support. (only works on unix)\nConfig for Sftp Service support.\nSled services support.\nConfig for Sled services support.\nCapabilities\nConfig for Sqlite support.\nSupabase service support\nConfig for supabase service support.\nCapabilities\nConfig for Surrealdb services support.\nOpenStack Swift’s REST API support. For more information …\nConfig for OpenStack Swift support.\nTiKV backend builder\nConfig for Tikv services support.\nupyun services support.\nConfig for upyun services support.\nVercel Cache backend support.\nConfig for Vercel Cache support.\nVercelBlob services support.\nConfig for VercelBlob services support.\nWebDAV backend support.\nConfig for WebDAV backend support.\nWebHDFS’s REST API support. There two implementations of …\nConfig for WebHDFS support.\nYandexDisk services support.\nConfig for YandexDisk services support.\nSet access_key_id of this backend.\nSet access_key_id of this backend.\nSet access_key_id of this backend.\nAccess key id for obs.\nAccess key id for oss.\naccess_key_id of this backend.\nSet access_key_secret of this backend.\nAccess key secret for oss.\nSet access_token of this backend.\nAccess token is used for temporary access to the Dropbox …\nAccess token is used for temporary access to the …\nset the bearer access token for OneDrive\nset the bearer access token for Vercel\nyandex disk oauth access_token. The valid token will looks …\nThe access_token of this backend.\naccess token for dropbox.\nAccess token for gdrive.\nbearer access token for OneDrive\nThe access token for Vercel.\nyandex disk oauth access_token.\nSet the account ID used to authenticate with CloudFlare.\nSet the account identifier for the cloudflare d1 service.\nThe account ID used to authenticate with CloudFlare. Used …\nSet the account id of cloudflare api.\nSet account_key of this backend.\nSet account_key of this backend.\nSet account_key of this backend.\nThe account key of Azblob service backend.\nAccount key of this backend.\nThe account key for azfile.\nSet account_name of this backend.\nSet account_name of this backend.\nSet account_name of this backend.\nThe account name of Azblob service backend.\nAccount name of this backend.\nThe account name for azfile.\nAllow anonymous requests.\nAllow anonymous will allow opendal to send request without …\nAllow anonymous will allow opendal to send request without …\nAllow opendal to send requests without signing when …\nAllow anonymous for oss.\nAllow anonymous will allow opendal to send request without …\napi_key of this backend.\napi_key of this backend.\nYour Apple id\napple_id of this backend.\napplication_key of this backend.\napplicationKey of this backend.\napplication_key_id of this backend.\nkeyID of this backend.\nSet temp dir for atomic write.\nSet temp dir for atomic write.\nSet temp dir for atomic write.\ntmp dir for atomic write\natomic_write_dir of this backend\natomic_write_dir of this backend\nset the authentication token for libsql service.\nAuthentication token for libsql service.\nSet maximum batch operations of this backend.\nSet maximum batch operations of this backend.\nSet maximum batch operations of this backend.\nThe maximum batch operations of Azblob service backend.\nThe size of max batch operations.\nSet maximum batch operations of this backend.\nSet branch of this backend or a commit ID. Default is main.\nName of the branch or a commit ID. Default is main.\nSet bucket name of this backend. You can find it in …\nSet bucket of this backend. The param is required.\nset the container’s name\nSet the bucket name of the MongoDB GridFs service to …\nSet bucket of this backend. The param is required.\nSet bucket name of this backend.\nSet bucket name of this backend.\nSet bucket name of this backend.\nbucket of this backend.\nbucket of this backend.\nBucket of this backend.\nbucket name\nThe bucket name of the MongoDB GridFs service to …\nBucket for obs.\nBucket for oss.\nbucket name of this backend.\nThe bucket for supabase service.\nbucket address of this backend.\nSet bucket id of this backend. You can find it in …\nSet bucket_id name of this backend.\nbucket id of this backend.\nbucket_id of this backend.\nBuilds the backend and returns the result of …\nBuilds the backend and returns the result of B2Backend.\nBuilds the backend and returns the result of …\nBuild a DbfsBackend.\nBuilds the backend and returns the result of GithubBackend.\nBuild a HuggingfaceBackend.\nBuilds the backend and returns the result of KoofrBackend.\nBuild a LakefsBackend.\nBuilds the backend and returns the result of PcloudBackend.\nBuilds the backend and returns the result of …\nBuild a SwiftBackend.\nBuilds the backend and returns the result of UpyunBackend.\nBuilds the backend and returns the result of …\nbuild the backend\nBuilds the backend and returns the result of …\nSet the certificate authority file path.\nSet the certificate authority file path.\ncertificate authority file path\ncertificate authority file path\nSet the certificate file path.\nSet the certificate file path.\ncert path\ncert path\nSet checksum algorithm of this backend. This is necessary …\nChecksum Algorithm to use when sending checksums in HTTP …\nSet the chunk size of the MongoDB GridFs service used to …\nThe chunk size of the MongoDB GridFs service used to break …\nSet client_id of this backend.\nSet the client id for Dropbox.\nSet the client id for GoogleDrive.\nThe client_id of this backend.\nclient_id for dropbox.\nClient id for gdrive.\nSet client_secret of this backend.\nSet the client secret for Dropbox.\nSet the client secret for GoogleDrive.\nThe client_secret of this backend.\nclient_secret for dropbox.\nClient secret for gdrive.\nset the network address of redis cluster service. This …\nnetwork address of the Redis cluster service. Can be “…\nSet the collection name of the MongoDB service to …\ncollection of this backend\nicloud config for web session request\nSet the config path for Foundationdb. If not set, will …\nconfig_path for the backend.\nSet the connection_string of the MongoDB service.\nSet the connection_string of the libsql service.\nSet the connection_string of the MongoDB service.\nSet the connection_string of the mysql service.\nSet the connection url string of the postgresql service.\nSet the connection_string of the sqlite service.\nSet the connection_string of the surrealdb service.\nThe connection string of the MongoDB service.\nConnection string for libsql service.\nconnection string of this backend\nThis connection string is used to connect to the mysql …\nThe URL should be with a scheme of either <code>postgres://</code> or …\nSet the connection_string of the sqlite service.\nThe connection string for surrealdb.\nSet container name of this backend.\nSet container of this backend.\nThe container name of Azblob service backend.\nThe container for Swift.\nset the base64 hashed credentials string used for OAuth2 …\nCredentials string for GCS service OAuth2 authentication.\nset the local path to credentials file which is used for …\nLocal path to credentials file for GCS service OAuth2 …\nAdding a customized credential load for service.\nSpecify the customized token loader used by this service.\nSet the database name of the MongoDB GridFs service to …\nSet the database name of the MongoDB service to read/write.\nSet the database of the surrealdb service for read/write.\nThe database name of the MongoDB GridFs service to …\ndatabase of this backend\nThe database for surrealdb.\nSet the database identifier for the cloudflare d1 service.\nSet the database id of cloudflare api.\nSet the path to the cacache data directory. Will create if …\nSet the path to the redb data directory. Will create if …\nSet the path to the rocksdb data directory. Will create if …\nSet the path to the sled data directory. Will create if …\nThat path to the cacache data directory.\npath to the redb data directory.\nThe path to the rocksdb data directory.\nThat path to the sled data directory.\nSet the path to the persy data directory. Will create if …\nThat path to the persy data file. The directory in the …\nset the db used in redis\nthe number of DBs redis can take is unlimited\nSet the default storage class for GCS.\nSet default storage_class for this backend.\nThe default storage class used by gcs.\ndefault storage_class for this backend.\nSet the default ttl for memcached services.\nSet the default ttl for redis services.\nThe default ttl for put operations.\nThe default ttl for put operations.\nSet the delegation token of this backend, used for …\nDelegation token for webhdfs.\nSet maximum delete operations of this backend.\nSet maximum delete operations of this backend.\nThe size of max delete operations.\nSet the maximum delete size of this backend.\nDetect region of S3 bucket.\nDisable config load so that opendal will not load config …\nDisable loading configuration from the environment.\nDisable config load so that opendal will not load config …\nDisable config load so that opendal will not load config …\nDisable loading configuration from the environment.\nDisable config load so that opendal will not load config …\nWebDAV Service doesn’t support copy.\nDisable load credential from ec2 metadata.\nDisable load credential from ec2 metadata.\nDisable batch listing\nDisable batch listing\nDisable stat with override so that opendal will not send …\nDisable stat with override so that opendal will not send …\nDisable attempting to load credentials from the GCE …\nDisable attempting to load credentials from the GCE …\nDisable write with if match so that opendal will not send …\nDisable write with if match so that opendal will not send …\nSet drive_type of this backend.\nThe drive_type of this backend.\nds_web_auth_token must be set in Session\nds_web_auth_token must be set in Session\nemail.\nKoofr email.\nEnable append capacity of this backend.\nEnable append capacity of this backend.\nenable the append capacity\nenable the append capacity\nset enable_copy for sftp backend. It requires the server …\nenable_copy of this backend\nSet bucket versioning status for this backend\nSet bucket versioning status for this backend\nis bucket versioning enabled for this bucket\nis bucket versioning enabled for this bucket\nEnable virtual host style so that opendal will send API …\nEnable virtual host style so that opendal will send API …\nSet encryption_algorithm of this backend.\nThe encryption algorithm of Azblob service backend.\nSet encryption_key of this backend.\nThe encryption key of Azblob service backend.\nSet encryption_key_sha256 of this backend.\nThe encryption key sha256 of Azblob service backend.\nendpoint of this backend.\nSet the server address for Atomicserver.\nSet endpoint of this backend\nSet endpoint of this backend.\nSet endpoint of this backend.\nSet endpoint of this backend.\nSet endpoint of this backend.\nset endpoint for ftp backend.\nset the endpoint GCS service uses\nSet the endpoint for ghac service.\nSet endpoint for http backend.\nSet endpoint if ipfs backend.\nSet endpoint for ipfs.\nendpoint.\nSet the endpoint of this backend.\nset the network address of memcached service.\nSet endpoint of this backend.\nSet endpoint of this backend.\nPcloud endpoint. https://api.pcloud.com for United States …\nset the network address of redis service.\nSet endpoint of this backend.\nendpoint of this backend.\nset endpoint for sftp backend. The format is same as …\nSet endpoint of this backend.\nSet the remote address of this backend\nSet endpoint for http backend.\nSet the remote address of this backend default to …\nendpoint of this backend.\nendpoint of this backend\nThe endpoint of Azblob service backend.\nEndpoint of this backend.\nThe endpoint for azfile.\nEndpoint of this backend.\nThe endpoint for dbfs.\nendpoint of this backend\nendpoint URI of GCS service, default is …\nThe endpoint for ghac service.\nendpoint of this backend\nIPFS gateway endpoint.\nEndpoint for ipfs.\nKoofr endpoint.\nBase url.\nnetwork address of the memcached service.\nEndpoint for obs.\nEndpoint for oss.\npCloud  endpoint address.\nnetwork address of the Redis service. Can be “…\nendpoint of this backend.\nendpoint address of this backend.\nendpoint of this backend\nThe endpoint for supabase service.\nThe endpoint for Swift.\nendpoint of this backend\nEndpoint for webhdfs.\nset the network address of etcd service.\nSet the network address of the TiKV service.\nnetwork address of the Etcd services. If use https, must …\nnetwork address of the TiKV service.\nSet external_id for this backend.\nexternal_id for this backend.\nSet filesystem name of this backend.\nFilesystem name of this backend.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nfrom_connection_string will make a builder from connection …\nSet the host addr of nebulagraph’s graphd server\nThe host addr of nebulagraph’s graphd server\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSet the name of the persy index. Will create if not exists.\nThat name of the persy index.\nSet the insecure connection to TiKV.\nwhether using insecure connection to TiKV\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nSet if your apple id in China mainland.\nenable the china origin China region <code>origin</code> Header needs …\nSet kerberos_ticket_cache_path of this backend\nkerberos_ticket_cache_path of this backend\nset key path for sftp backend.\nSet the authorization key for this backend Do not set this …\nkey of this backend\nThe key for supabase service.\nSet the key field name of the d1 service to read/write.\nSet the key field name of the libsql service to read/write.\nSet the key field name of the MongoDB service to …\nSet the key field name of the mysql service to read/write.\nSet the key field name of the NebulaGraph service to …\nSet the key field name of the postgresql service to …\nSet the key field name of the sqlite service to read/write.\nSet the key field name of the surrealdb service for …\nSet the key field of D1 Database.\nKey field name for libsql service.\nkey field of this backend\nThe key field name for mysql.\nThe key field name of the NebulaGraph service to …\nthe key field of postgresql\nSet the key field name of the sqlite service to read/write.\nThe key field for surrealdb.\nSet the key file path.\nSet the key file path.\nkey path\nkey path\nset known_hosts strategy for sftp backend. available …\nknown_hosts_strategy of this backend\nSets the max capacity of the cache.\nSets the max capacity of the cache.\nSets the max capacity of the cache.\nSets the max capacity of the cache.\nName for this cache instance.\nName for this cache instance.\nSet name_node of this backend.\nname node of this backend\nSet the namespace of the surrealdb service for read/write.\nThe namespace for surrealdb.\nSet the namespace ID.\nThe namespace ID. Used as URI path parameter.\nSets the segments number of the cache.\nSet oidc_provider_arn for this backend.\n<code>oidc_provider_arn</code> will be loaded from\nSet oidc_token_file for this backend.\n<code>oidc_token_file</code> will be loaded from\noperator of this backend.\nusername of this backend.\nSet Github repo owner.\nGitHub repo owner.\nSet the parent resource id (url) that Atomicserver uses to …\nparent_resource_id of this backend\nset the password for etcd\nset password for ftp backend.\nset password for http backend\nYour Apple id password\nKoofr application password.\nSet password of this backend. This is required.\nset the password.\nSet the password of nebulagraph’s graphd server\nPcloud password.\nset the password for redis\npassword of this backend.\nSet the password of the surrealdb service for signin.\npassword of this backend.\nset the password for Webdav\nthe password for authentication\npassword of this backend\npassword of this backend\npassword of this backend.\npassword of this backend. (Must be the application …\nPassword for Lakefs basic authentication.\nMemcached password, optional.\nThe password of nebulagraph’s graphd server\npCloud password.\nthe password for authentication\npassword of this backend.\nThe password for surrealdb.\npassword of this backend.\npassword of this backend\nSet the host port of nebulagraph’s graphd server\nThe host port of nebulagraph’s graphd server\nSet the predefined acl for GCS.\nThe predefined acl for GCS.\nSet an endpoint for generating presigned urls.\nPresign endpoint for oss.\nSet the private key for agent used for Atomicserver.\nprivate_key of this backend\nSet the public key for agent used for Atomicserver. For …\npublic_key of this backend\nSet refresh_token of this backend.\nRefresh token is used for long term access to the Dropbox …\nRefresh token is used for long term access to the …\nThe refresh_token of this backend.\nrefresh_token for dropbox.\nRefresh token for gdrive.\nRegion represent the signing region of this endpoint. This …\nRegion represent the signing region of this endpoint. This …\nSet Github repo name.\nGitHub repo name.\nSet repo id of this backend. This is required.\nRepo id of this backend.\nSet repo name of this backend.\nrepo_name of this backend.\nSet repo type of this backend. Default is model.\nRepo type of this backend. Default is model.\nSet the repository of this backend.\nThe repository name\nSet revision of this backend. Default is main.\nRevision of this backend.\nSet role_arn for this backend.\nSet role_arn for this backend.\nIf <code>role_arn</code> is set, we will use already known config as …\nrole_arn for this backend.\nSet role_session_name for this backend.\nSet role_session_name for this backend.\nrole_session_name for this backend.\nrole_session_name for this backend.\nSet the root of this backend.\nSet root of this backend.\nSet the root for Atomicserver.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet the root within this backend.\nSet root for Compfs\nSet root of this backend.\nset the working directory, all operations will be …\nSet the root for dashmap.\nSet root of this backend.\nSet the root directory for dropbox.\nset the working directory, all operations will be …\nSet the root for Foundationdb.\nSet root for backend.\nset root path for ftp backend.\nset the working directory root of backend\nSet root path of GoogleDrive folder.\nset the working directory root of backend\nSet root of this backend.\nSet the working directory, all operations will be …\nSet root of this backend.\nSet root of this backend.\nSet root path of http backend.\nSet root of this backend.\nSet root of this backend.\nSet root of ipfs backend.\nSet root for ipfs.\nSet root of this backend.\nSet root of this backend.\nset the working directory, all operations will be …\nset the working directory, all operations will be …\nSet the root for BTreeMap.\nSet root path of this backend\nSet root path of this backend\nSet the working directory, all operations will be …\nSet root of this backend.\nset the working directory, all operations will be …\nset the working directory, all operations will be …\nSet root of this backend.\nSet root path of OneDrive folder.\nSet root of this backend.\nSet root of this backend.\nSet the working directory, all operations will be …\nSet the root for Redb.\nset the working directory, all operations will be …\nset the working directory, all operations will be …\nSet root of this backend.\nSet root of this backend.\nset root path for sftp backend. It uses the default …\nSet the root for sled.\nset the working directory, all operations will be …\nSet root of this backend.\nset the working directory, all operations will be …\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root path of http backend.\nSet the working directory of this backend\nSet root of this backend.\nThe Root of this backend.\nroot of this backend.\nwork dir of this backend\nThe root of Azblob service backend.\nRoot of this backend.\nThe root path for azfile.\nroot of this backend.\nroot of this backend.\nRoot within this backend.\nroot of this backend.\nRoot of this backend.\nSet the working directory of OpenDAL.\nThe root path for dashmap.\nThe root for dbfs.\nroot path for dropbox.\nthe working directory of the etcd service. Can be “…\nroot of the backend.\nroot dir for backend\nroot of this backend\nroot URI, all operations happens under <code>root</code>\nThe root for gdrive\nThe root path for ghac.\nroot of this backend.\nThe working directory, all operations will be performed …\nwork dir of this backend\nwork dir of this backend\nroot of this backend\nRoot of this backend. Can be “/path/to/dir”.\nroot of this backend.\nIPFS root.\nRoot for ipfs.\nroot of this backend.\nRoot of this backend. Can be “/path/to/dir”.\nRoot for libsql service.\nthe working directory of the service. Can be “…\nroot of the backend.\nroot path of this backend\nroot path of this backend\nroot of this backend\nThe Root of this backend.\nThe root for mysql.\nThe root for NebulaGraph\nRoot for obs.\nroot path of OneDrive folder.\nRoot for oss.\nroot of this backend.\nRoot of this backend.\nThe root for redb.\nthe working directory of the Redis service. Can be “…\nthe working directory of the service. Can be “…\nroot of this backend.\nroot of this backend.\nroot of this backend\nThe root for sled.\nset the working directory, all operations will be …\nThe root for supabase service.\nThe root for surrealdb.\nThe root for Swift.\nroot of this backend.\nroot of this backend.\nroot of this backend\nRoot for webhdfs.\nroot of this backend.\nSet the runtime token for ghac service.\nThe runtime token for ghac service.\nSet sas_token of this backend.\nThe sas token of Azblob service backend.\nThe sas token for azfile.\nset the GCS service scope\nScope for gcs.\nSet secret_access_key of this backend.\nSet secret_access_key of this backend.\nSecret access key for obs.\nsecret_access_key of this backend.\nSet secret_id of this backend.\nSecret ID of this backend.\nSet secret_key of this backend.\nSecret key of this backend.\nSet temporary credential used in AWS S3 connections\nSet the name of the persy segment. Will create if not …\nThat name of the persy segment.\nSets the segments number of the cache.\nSet server_side_encryption for this backend.\nSet server_side_encryption for this backend.\nServer side encryption for oss.\nserver_side_encryption for this backend.\nSet server_side_encryption_aws_kms_key_id for this backend\nserver_side_encryption_aws_kms_key_id for this backend\nSet server_side_encryption_customer_algorithm for this …\nserver_side_encryption_customer_algorithm for this backend.\nSet server_side_encryption_customer_key for this backend.\nserver_side_encryption_customer_key for this backend.\nSet server_side_encryption_customer_key_md5 for this …\nSet server_side_encryption_customer_key_md5 for this …\nSet server_side_encryption_key_id for this backend.\nServer side encryption key id for oss.\nEnable server side encryption with aws managed kms key\nEnable server side encryption with customer key.\nEnable server side encryption with customer key.\nEnable server side encryption with customer managed kms key\nEnable server side encryption with s3 managed key\nSet the GCS service account.\nService Account for gcs.\nSet temporary credential used in AWS S3 connections\nsession_token (aka, security token) of this backend.\nSet file share name of this backend.\nThe share name for azfile.\nSet the space name of nebulagraph’s graphd server\nThe space name of nebulagraph’s graphd server\nSet sts_endpoint for this backend.\n<code>sts_endpoint</code> will be loaded from\nSet the table name of the d1 service to read/write.\nSet the table name of the libsql service to read/write.\nSet the table name of the mysql service to read/write.\nSet the table name of the postgresql service to read/write.\nSet the table name for Redb.\nSet the table name of the sqlite service to read/write.\nSet the table name of the surrealdb service for read/write.\nSet the table of D1 Database.\nTable name for libsql service.\nThe table name for mysql.\nthe table of postgresql\nThe table name for redb.\nSet the table name of the sqlite service to read/write.\nThe table for surrealdb.\nSet the tag name of nebulagraph’s graphd server\nThe tag name of nebulagraph’s graphd server\nSets the time to idle of the cache.\nSets the time to idle of the cache.\nSets the time to idle of the cache.\nSets the time to idle of the cache.\nSets the time to live of the cache.\nSets the time to live of the cache.\nSets the time to live of the cache.\nSets the time to live of the cache.\nSet the token used to authenticate with CloudFlare.\nSet api token for the cloudflare d1 service.\nSet the token of this backend.\nProvide the OAuth2 token to use.\nGithub access_token.\nset bearer token for http backend\nSet the token of this backend.\nSet the token of this backend.\nVercel Blob token.\nset the bearer token for Webdav\nThe token used to authenticate with CloudFlare.\nSet the token of cloudflare api.\nThe token for dbfs.\nA Google Cloud OAuth2 token.\nGitHub access_token.\ntoken of this backend\nToken of this backend.\nThe token for Swift.\nvercel blob token.\ntoken of this backend\nSet the tree for sled.\nThe tree for sled.\nTrust token and ds_web_auth_token is used for temporary …\nSession\nSet url of this backend.\nurl of this backend\nset user for ftp backend.\nSet user of this backend\nset user for sftp backend.\nuser of this backend\nuser of this backend\nuser of this backend\nset the username for etcd\nset username for http backend\nSet username of this backend. This is required.\nset the username.\nSet the username of nebulagraph’s graphd server\nPcloud username.\nset the username for redis\nusername of this backend.\nSet the username of the surrealdb service for signin.\nset the username for Webdav\nthe username to connect etcd service.\nusername of this backend\nUsername for Lakefs basic authentication.\nMemcached username, optional.\nThe username of nebulagraph’s graphd server\npCloud username.\nthe username to connect redis service.\nusername of this backend.\nThe username for surrealdb.\nusername of this backend\nSet the value field name of the d1 service to read/write.\nSet the value field name of the libsql service to …\nSet the value field name of the MongoDB service to …\nSet the value field name of the mysql service to …\nSet the value field name of the NebulaGraph service to …\nSet the value field name of the postgresql service to …\nSet the value field name of the sqlite service to …\nSet the value field name of the surrealdb service for …\nSet the value field of D1 Database.\nValue field name for libsql service.\nvalue field of this backend\nThe value field name for mysql.\nThe value field name of the NebulaGraph service to …\nthe value field of postgresql\nSet the value field name of the sqlite service to …\nThe value field for surrealdb.\nset the version that used by cache.\nThe version that used by cache.")